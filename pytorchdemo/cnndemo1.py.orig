'''
@author: neo
@file: cnndemo1.py
@time: 2019/5/4 10:41
'''
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.autograd import Variable

class CNNnet(torch.nn.Module):
    def __init__(self):
        super(CNNnet, self).__init__()
        self.conv1 = torch.nn.Sequential(
            torch.nn.Conv2d(in_channels=3,    # input 3,16,400,1400
                            out_channels=16, #16ä¸ªfilterï¼Œæå6ä¸ªç‰¹å¾ä½œä¸ºè¾“å‡
            torch.nn.Conv2d(in_channels=3,    # input 3,16,400,1400
                            out_channels=16, #16ä¸ªfilterï¼Œæå6ä¸ªç‰¹å¾ä½œä¸ºè¾“å‡
                            kernel_size=5,
                            stride=1,
                            padding=2),
            torch.nn.BatchNorm2d(16),  # æ˜¯ä¸€ä¸ªfilter,æå–ç‰¹å¾ï¼ç‰¹å¾çª
            torch.nn.ReLU(),
                            stride=1,
                            padding=2),
            torch.nn.BatchNorm2d(16),  # æ˜¯ä¸€ä¸ªfilter,æå–ç‰¹å¾ï¼ç‰¹å¾çª
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2)  # æ± åŒ–å±out 16,200,700
            torch.nn.MaxPool2d(2)  # æ± åŒ–å±out 16,200,700
        )
        self.conv2 = torch.nn.Sequential(
            torch.nn.Conv2d(16, 32, 5, 1, 2),
            torch.nn.BatchNorm2d(32),
            torch.nn.ReLU(),
            torch.nn.Conv2d(16, 32, 5, 1, 2),
            torch.nn.BatchNorm2d(32),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2)  # 32,100,350
            torch.nn.MaxPool2d(2)  # 32,100,350
        )
        self.conv3 = torch.nn.Sequential(
            torch.nn.Conv2d(32, 32, 5, 1, 2),
            torch.nn.BatchNorm2d(32),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2)  # 32 50 175
        )
        # self.conv4 = torch.nn.Sequential(
        #
        #     torch.nn.Conv2d(32, 64, 5, 1, 2),  # 2*32*48
        #     torch.nn.BatchNorm2d(64),
        #     torch.nn.ReLU(),
        #     torch.nn.MaxPool2d(2)  # 64,25,87
        # )
        # self.mlp1 = torch.nn.Linear(2*2*2*16*24, 2000)
        self.mlp1 = torch.nn.Linear(32*176*50, 1000)
        self.mlp2 = torch.nn.Linear(1000, 2)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)

        # x = self.conv4(x)
        # print(x.shape)
        # t = x.size(0)
        x = self.mlp1(x.view(x.size(0), -1))
<<<<<<< HEAD
        out = self.mlp2(x)
        return out
=======
        x = self.mlp2(x)
        return x
        x = self.mlp2(x)
        return x
>>>>>>> 8231c02... update


train_data = torchvision.datasets.ImageFolder('D:/debug/python/pytorchdemo/pic/train',
                                            transform=transforms.Compose([
                                                # transforms.Scale(512),
                                                # transforms.CenterCrop(256),
                                                transforms.ToTensor()])
                                            )
test_data = torchvision.datasets.ImageFolder('D:/debug/python/pytorchdemo/pic/val',
                                            transform=transforms.Compose([
                                                # transforms.Scale(512),
                                                # transforms.CenterCrop(256),
                                                transforms.ToTensor()])
                                            )
train_loader = torch.utils.data.DataLoader(train_data, batch_size=2,shuffle=True)
test_loader = torch.utils.data.DataLoader(test_data,batch_size=2, shuffle=True)

model = CNNnet()
loss_func = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.02)  # è®¾ç½®å­¦ä¹ æ–¹æ³•
# num_epochs = 100 # è®¾ç½®è®­ç»ƒæ¬¡æ•°
# print(model)

def train_fun():
    epochs = 0
    loss_list = []
    # for eopch in range(EPOCH):
    for data in (train_loader):
        b_x,b_y=data
        b_x,b_y=Variable(b_x),Variable(b_y)
        out_put=model(b_x)
        loss=loss_func(out_put,b_y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        #
        if epochs < 20:
            epochs += 1
            print('Epoch: ', epochs, 'loss: ', float(loss))
            loss_list.append(float(loss))
        # else:
        #     epochs += 1

    return loss_list


# criterion = nn.MSELoss()  # è®¾å®šè¯¯å·®å‡½æ•°
def test_fun():
    eval_loss = 0
    eval_acc = 0
    # for eopch in range(EPOCH):
    for data in (test_loader):
        b_x, b_y = data
        b_x, b_y = Variable(b_x), Variable(b_y)  # b_x æ˜img b_yæ˜¯æ ‡ç­
        out_put = model(b_x)
        loss = loss_func(out_put, b_y)
        eval_loss += loss.data.item() * b_y.size(0)
        _, pred = torch.max(out_put, 1)
        # print("pred",pred,b_y)
        num_correct = (pred == b_y).sum()
        eval_acc += num_correct.item()
        # print(eval_acc)
        print('Test Loss: {:.4f}, Acc: {:.4f}'.format(
        eval_loss / (len(test_data)),
        eval_acc / (len(test_data)), 100. * eval_acc / len(test_data)
    ))



# params = list(model.parameters())
# print(len(params))
# print(model)
# print(params[0].size())  # conv1's .weight
# train_fun()
# torch.save(model,"mycnn1")
<<<<<<< HEAD
# test_fun()
print("model ok")
=======
test_fun()
>>>>>>> 8231c02... update
